{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: Main Changes of Original Model\n",
    "## Try Different Parameters in Each Model for Multiple Times (Detailed Outputs in the Excel Files - Post On BB)\n",
    "## 2 Add a XGBoost At the End of This File\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD DURATION:  0:00:02.354226\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Libraries to load\n",
    "# !pip install lightgbm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "print('LOAD DURATION: ', datetime.now() - start_time) # load time about 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 32 s, total: 1min 54s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vars_total = pd.read_csv('vars_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = vars_total[['record',\n",
    "                   'fulladdress_count_30',\n",
    "                   'ssn_firstname_count_30',\n",
    "                   'homephone_count_3',\n",
    "                   'ssn_dob_count_30',\n",
    "                   'fulladdress_homephone_count_30',\n",
    "                   'fulladdress_count_0_by_30',\n",
    "                    'fulladdress_unique_count_for_dob_homephone_60',\n",
    "                    'fulladdress_unique_count_for_ssn_name_60',\n",
    "                    'fulladdress_unique_count_for_ssn_lastname_60',\n",
    "                    'fulladdress_unique_count_for_ssn_60',\n",
    "                    'fulladdress_unique_count_for_ssn_fulladdress_60',\n",
    "                    'fulladdress_unique_count_for_ssn_zip5_60',\n",
    "                    'fulladdress_unique_count_for_name_dob_60',\n",
    "                    'fulladdress_unique_count_for_fulladdress_dob_60',\n",
    "                   'fulladdress_unique_count_for_ssn_name_30',\n",
    "                    'fulladdress_unique_count_for_ssn_lastname_30',\n",
    "                    'fulladdress_unique_count_for_ssn_fulladdress_30',\n",
    "                    'fulladdress_unique_count_for_ssn_30',\n",
    "                    'fulladdress_unique_count_for_ssn_zip5_30',\n",
    "                    'fulladdress_unique_count_for_ssn_name_dob_30',\n",
    "                    'fulladdress_count_0_by_14',\n",
    "                    'fulladdress_unique_count_for_name_fulladdress_30',\n",
    "                    'fulladdress_unique_count_for_name_dob_30',\n",
    "                     'name_dob_count_30',\n",
    "                    'ssn_name_dob_count_30',\n",
    "                   'fraud_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to cap variables. For some problems it helps\n",
    "Clip = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4441: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "vars.rename(columns={'fraud_label':'Fraud'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14393"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['Fraud'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>fulladdress_count_30</th>\n",
       "      <th>ssn_firstname_count_30</th>\n",
       "      <th>homephone_count_3</th>\n",
       "      <th>ssn_dob_count_30</th>\n",
       "      <th>fulladdress_homephone_count_30</th>\n",
       "      <th>fulladdress_count_0_by_30</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_name_60</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_lastname_60</th>\n",
       "      <th>...</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_fulladdress_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_zip5_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_name_dob_30</th>\n",
       "      <th>fulladdress_count_0_by_14</th>\n",
       "      <th>fulladdress_unique_count_for_name_fulladdress_30</th>\n",
       "      <th>fulladdress_unique_count_for_name_dob_30</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>ssn_name_dob_count_30</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   record  fulladdress_count_30  ssn_firstname_count_30  homephone_count_3  \\\n",
       "0       1                     1                       1                  1   \n",
       "1       2                     1                       1                  1   \n",
       "2       3                     1                       1                  1   \n",
       "3       4                     1                       1                  1   \n",
       "4       5                     1                       1                  1   \n",
       "5       6                     1                       1                  1   \n",
       "6       7                     1                       1                  1   \n",
       "7       8                     1                       1                  1   \n",
       "8       9                     1                       1                  1   \n",
       "9      10                     1                       1                  1   \n",
       "\n",
       "   ssn_dob_count_30  fulladdress_homephone_count_30  \\\n",
       "0                 1                               1   \n",
       "1                 1                               1   \n",
       "2                 1                               1   \n",
       "3                 1                               1   \n",
       "4                 1                               1   \n",
       "5                 1                               1   \n",
       "6                 1                               1   \n",
       "7                 1                               1   \n",
       "8                 1                               1   \n",
       "9                 1                               1   \n",
       "\n",
       "   fulladdress_count_0_by_30  fulladdress_unique_count_for_dob_homephone_60  \\\n",
       "0                       30.0                                              1   \n",
       "1                       30.0                                              1   \n",
       "2                       30.0                                              1   \n",
       "3                       30.0                                              1   \n",
       "4                       30.0                                              1   \n",
       "5                       30.0                                              1   \n",
       "6                       30.0                                              1   \n",
       "7                       30.0                                              1   \n",
       "8                       30.0                                              1   \n",
       "9                       30.0                                              1   \n",
       "\n",
       "   fulladdress_unique_count_for_ssn_name_60  \\\n",
       "0                                         1   \n",
       "1                                         1   \n",
       "2                                         1   \n",
       "3                                         1   \n",
       "4                                         1   \n",
       "5                                         1   \n",
       "6                                         1   \n",
       "7                                         1   \n",
       "8                                         1   \n",
       "9                                         1   \n",
       "\n",
       "   fulladdress_unique_count_for_ssn_lastname_60  ...  \\\n",
       "0                                             1  ...   \n",
       "1                                             1  ...   \n",
       "2                                             1  ...   \n",
       "3                                             1  ...   \n",
       "4                                             1  ...   \n",
       "5                                             1  ...   \n",
       "6                                             1  ...   \n",
       "7                                             1  ...   \n",
       "8                                             1  ...   \n",
       "9                                             1  ...   \n",
       "\n",
       "   fulladdress_unique_count_for_ssn_fulladdress_30  \\\n",
       "0                                                1   \n",
       "1                                                1   \n",
       "2                                                1   \n",
       "3                                                1   \n",
       "4                                                1   \n",
       "5                                                1   \n",
       "6                                                1   \n",
       "7                                                1   \n",
       "8                                                1   \n",
       "9                                                1   \n",
       "\n",
       "   fulladdress_unique_count_for_ssn_30  \\\n",
       "0                                    1   \n",
       "1                                    1   \n",
       "2                                    1   \n",
       "3                                    1   \n",
       "4                                    1   \n",
       "5                                    1   \n",
       "6                                    1   \n",
       "7                                    1   \n",
       "8                                    1   \n",
       "9                                    1   \n",
       "\n",
       "   fulladdress_unique_count_for_ssn_zip5_30  \\\n",
       "0                                         1   \n",
       "1                                         1   \n",
       "2                                         1   \n",
       "3                                         1   \n",
       "4                                         1   \n",
       "5                                         1   \n",
       "6                                         1   \n",
       "7                                         1   \n",
       "8                                         1   \n",
       "9                                         1   \n",
       "\n",
       "   fulladdress_unique_count_for_ssn_name_dob_30  fulladdress_count_0_by_14  \\\n",
       "0                                             1                       14.0   \n",
       "1                                             1                       14.0   \n",
       "2                                             1                       14.0   \n",
       "3                                             1                       14.0   \n",
       "4                                             1                       14.0   \n",
       "5                                             1                       14.0   \n",
       "6                                             1                       14.0   \n",
       "7                                             1                       14.0   \n",
       "8                                             1                       14.0   \n",
       "9                                             1                       14.0   \n",
       "\n",
       "   fulladdress_unique_count_for_name_fulladdress_30  \\\n",
       "0                                                 1   \n",
       "1                                                 1   \n",
       "2                                                 1   \n",
       "3                                                 1   \n",
       "4                                                 1   \n",
       "5                                                 1   \n",
       "6                                                 1   \n",
       "7                                                 1   \n",
       "8                                                 1   \n",
       "9                                                 1   \n",
       "\n",
       "   fulladdress_unique_count_for_name_dob_30  name_dob_count_30  \\\n",
       "0                                         1                  1   \n",
       "1                                         1                  1   \n",
       "2                                         1                  1   \n",
       "3                                         1                  1   \n",
       "4                                         1                  1   \n",
       "5                                         1                  1   \n",
       "6                                         1                  1   \n",
       "7                                         1                  1   \n",
       "8                                         1                  1   \n",
       "9                                         1                  1   \n",
       "\n",
       "   ssn_name_dob_count_30  Fraud  \n",
       "0                      1      0  \n",
       "1                      1      1  \n",
       "2                      1      0  \n",
       "3                      1      0  \n",
       "4                      1      0  \n",
       "5                      1      0  \n",
       "6                      1      0  \n",
       "7                      1      0  \n",
       "8                      1      0  \n",
       "9                      1      0  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>fulladdress_count_30</th>\n",
       "      <th>ssn_firstname_count_30</th>\n",
       "      <th>homephone_count_3</th>\n",
       "      <th>ssn_dob_count_30</th>\n",
       "      <th>fulladdress_homephone_count_30</th>\n",
       "      <th>fulladdress_count_0_by_30</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_name_60</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_lastname_60</th>\n",
       "      <th>...</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_fulladdress_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_zip5_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_name_dob_30</th>\n",
       "      <th>fulladdress_count_0_by_14</th>\n",
       "      <th>fulladdress_unique_count_for_name_fulladdress_30</th>\n",
       "      <th>fulladdress_unique_count_for_name_dob_30</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>ssn_name_dob_count_30</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>500000.500000</td>\n",
       "      <td>1.064624</td>\n",
       "      <td>1.048903</td>\n",
       "      <td>1.449296</td>\n",
       "      <td>1.046097</td>\n",
       "      <td>1.048207</td>\n",
       "      <td>29.491030</td>\n",
       "      <td>1.044485</td>\n",
       "      <td>1.038698</td>\n",
       "      <td>1.038636</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036240</td>\n",
       "      <td>1.036240</td>\n",
       "      <td>1.036240</td>\n",
       "      <td>1.038982</td>\n",
       "      <td>13.866195</td>\n",
       "      <td>1.035916</td>\n",
       "      <td>1.038716</td>\n",
       "      <td>1.046295</td>\n",
       "      <td>1.045940</td>\n",
       "      <td>0.014393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288675.278933</td>\n",
       "      <td>0.633831</td>\n",
       "      <td>0.499029</td>\n",
       "      <td>0.861622</td>\n",
       "      <td>0.496315</td>\n",
       "      <td>0.507682</td>\n",
       "      <td>2.831175</td>\n",
       "      <td>0.617953</td>\n",
       "      <td>0.613817</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608032</td>\n",
       "      <td>0.608032</td>\n",
       "      <td>0.608032</td>\n",
       "      <td>0.610242</td>\n",
       "      <td>1.015231</td>\n",
       "      <td>0.607661</td>\n",
       "      <td>0.609942</td>\n",
       "      <td>0.496914</td>\n",
       "      <td>0.496147</td>\n",
       "      <td>0.119104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.304348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>250000.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>500000.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>750000.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               record  fulladdress_count_30  ssn_firstname_count_30  \\\n",
       "count  1000000.000000        1000000.000000          1000000.000000   \n",
       "mean    500000.500000              1.064624                1.048903   \n",
       "std     288675.278933              0.633831                0.499029   \n",
       "min          1.000000              1.000000                1.000000   \n",
       "25%     250000.750000              1.000000                1.000000   \n",
       "50%     500000.500000              1.000000                1.000000   \n",
       "75%     750000.250000              1.000000                1.000000   \n",
       "max    1000000.000000             30.000000               34.000000   \n",
       "\n",
       "       homephone_count_3  ssn_dob_count_30  fulladdress_homephone_count_30  \\\n",
       "count     1000000.000000    1000000.000000                  1000000.000000   \n",
       "mean            1.449296          1.046097                        1.048207   \n",
       "std             0.861622          0.496315                        0.507682   \n",
       "min             1.000000          1.000000                        1.000000   \n",
       "25%             1.000000          1.000000                        1.000000   \n",
       "50%             1.000000          1.000000                        1.000000   \n",
       "75%             2.000000          1.000000                        1.000000   \n",
       "max            32.000000         34.000000                       30.000000   \n",
       "\n",
       "       fulladdress_count_0_by_30  \\\n",
       "count             1000000.000000   \n",
       "mean                   29.491030   \n",
       "std                     2.831175   \n",
       "min                     1.304348   \n",
       "25%                    30.000000   \n",
       "50%                    30.000000   \n",
       "75%                    30.000000   \n",
       "max                    30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_dob_homephone_60  \\\n",
       "count                                 1000000.000000   \n",
       "mean                                        1.044485   \n",
       "std                                         0.617953   \n",
       "min                                         1.000000   \n",
       "25%                                         1.000000   \n",
       "50%                                         1.000000   \n",
       "75%                                         1.000000   \n",
       "max                                        30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_name_60  \\\n",
       "count                            1000000.000000   \n",
       "mean                                   1.038698   \n",
       "std                                    0.613817   \n",
       "min                                    1.000000   \n",
       "25%                                    1.000000   \n",
       "50%                                    1.000000   \n",
       "75%                                    1.000000   \n",
       "max                                   30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_lastname_60  ...  \\\n",
       "count                                1000000.000000  ...   \n",
       "mean                                       1.038636  ...   \n",
       "std                                        0.613757  ...   \n",
       "min                                        1.000000  ...   \n",
       "25%                                        1.000000  ...   \n",
       "50%                                        1.000000  ...   \n",
       "75%                                        1.000000  ...   \n",
       "max                                       30.000000  ...   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_fulladdress_30  \\\n",
       "count                                   1000000.000000   \n",
       "mean                                          1.036240   \n",
       "std                                           0.608032   \n",
       "min                                           1.000000   \n",
       "25%                                           1.000000   \n",
       "50%                                           1.000000   \n",
       "75%                                           1.000000   \n",
       "max                                          30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_30  \\\n",
       "count                       1000000.000000   \n",
       "mean                              1.036240   \n",
       "std                               0.608032   \n",
       "min                               1.000000   \n",
       "25%                               1.000000   \n",
       "50%                               1.000000   \n",
       "75%                               1.000000   \n",
       "max                              30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_zip5_30  \\\n",
       "count                            1000000.000000   \n",
       "mean                                   1.036240   \n",
       "std                                    0.608032   \n",
       "min                                    1.000000   \n",
       "25%                                    1.000000   \n",
       "50%                                    1.000000   \n",
       "75%                                    1.000000   \n",
       "max                                   30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_name_dob_30  \\\n",
       "count                                1000000.000000   \n",
       "mean                                       1.038982   \n",
       "std                                        0.610242   \n",
       "min                                        1.000000   \n",
       "25%                                        1.000000   \n",
       "50%                                        1.000000   \n",
       "75%                                        1.000000   \n",
       "max                                       30.000000   \n",
       "\n",
       "       fulladdress_count_0_by_14  \\\n",
       "count             1000000.000000   \n",
       "mean                   13.866195   \n",
       "std                     1.015231   \n",
       "min                     0.636364   \n",
       "25%                    14.000000   \n",
       "50%                    14.000000   \n",
       "75%                    14.000000   \n",
       "max                    14.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_name_fulladdress_30  \\\n",
       "count                                    1000000.000000   \n",
       "mean                                           1.035916   \n",
       "std                                            0.607661   \n",
       "min                                            1.000000   \n",
       "25%                                            1.000000   \n",
       "50%                                            1.000000   \n",
       "75%                                            1.000000   \n",
       "max                                           30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_name_dob_30  name_dob_count_30  \\\n",
       "count                            1000000.000000     1000000.000000   \n",
       "mean                                   1.038716           1.046295   \n",
       "std                                    0.609942           0.496914   \n",
       "min                                    1.000000           1.000000   \n",
       "25%                                    1.000000           1.000000   \n",
       "50%                                    1.000000           1.000000   \n",
       "75%                                    1.000000           1.000000   \n",
       "max                                   30.000000          34.000000   \n",
       "\n",
       "       ssn_name_dob_count_30           Fraud  \n",
       "count         1000000.000000  1000000.000000  \n",
       "mean                1.045940        0.014393  \n",
       "std                 0.496147        0.119104  \n",
       "min                 1.000000        0.000000  \n",
       "25%                 1.000000        0.000000  \n",
       "50%                 1.000000        0.000000  \n",
       "75%                 1.000000        0.000000  \n",
       "max                34.000000        1.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud\n",
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_save = vars['record']\n",
    "Y_save = pd.DataFrame(vars.loc[:,'Fraud'])\n",
    "Y_save.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and truncate field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_count_30</th>\n",
       "      <th>ssn_firstname_count_30</th>\n",
       "      <th>homephone_count_3</th>\n",
       "      <th>ssn_dob_count_30</th>\n",
       "      <th>fulladdress_homephone_count_30</th>\n",
       "      <th>fulladdress_count_0_by_30</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_name_60</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_lastname_60</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_60</th>\n",
       "      <th>...</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_lastname_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_fulladdress_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_zip5_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_name_dob_30</th>\n",
       "      <th>fulladdress_count_0_by_14</th>\n",
       "      <th>fulladdress_unique_count_for_name_fulladdress_30</th>\n",
       "      <th>fulladdress_unique_count_for_name_dob_30</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>ssn_name_dob_count_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.064624</td>\n",
       "      <td>1.048903</td>\n",
       "      <td>1.449296</td>\n",
       "      <td>1.046097</td>\n",
       "      <td>1.048207</td>\n",
       "      <td>29.491030</td>\n",
       "      <td>1.044485</td>\n",
       "      <td>1.038698</td>\n",
       "      <td>1.038636</td>\n",
       "      <td>1.038559</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036291</td>\n",
       "      <td>1.036240</td>\n",
       "      <td>1.036240</td>\n",
       "      <td>1.036240</td>\n",
       "      <td>1.038982</td>\n",
       "      <td>13.866195</td>\n",
       "      <td>1.035916</td>\n",
       "      <td>1.038716</td>\n",
       "      <td>1.046295</td>\n",
       "      <td>1.045940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.633831</td>\n",
       "      <td>0.499029</td>\n",
       "      <td>0.861622</td>\n",
       "      <td>0.496315</td>\n",
       "      <td>0.507682</td>\n",
       "      <td>2.831175</td>\n",
       "      <td>0.617953</td>\n",
       "      <td>0.613817</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>0.613686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608074</td>\n",
       "      <td>0.608032</td>\n",
       "      <td>0.608032</td>\n",
       "      <td>0.608032</td>\n",
       "      <td>0.610242</td>\n",
       "      <td>1.015231</td>\n",
       "      <td>0.607661</td>\n",
       "      <td>0.609942</td>\n",
       "      <td>0.496914</td>\n",
       "      <td>0.496147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.304348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fulladdress_count_30  ssn_firstname_count_30  homephone_count_3  \\\n",
       "count        1000000.000000          1000000.000000     1000000.000000   \n",
       "mean               1.064624                1.048903           1.449296   \n",
       "std                0.633831                0.499029           0.861622   \n",
       "min                1.000000                1.000000           1.000000   \n",
       "25%                1.000000                1.000000           1.000000   \n",
       "50%                1.000000                1.000000           1.000000   \n",
       "75%                1.000000                1.000000           2.000000   \n",
       "max               30.000000               34.000000          32.000000   \n",
       "\n",
       "       ssn_dob_count_30  fulladdress_homephone_count_30  \\\n",
       "count    1000000.000000                  1000000.000000   \n",
       "mean           1.046097                        1.048207   \n",
       "std            0.496315                        0.507682   \n",
       "min            1.000000                        1.000000   \n",
       "25%            1.000000                        1.000000   \n",
       "50%            1.000000                        1.000000   \n",
       "75%            1.000000                        1.000000   \n",
       "max           34.000000                       30.000000   \n",
       "\n",
       "       fulladdress_count_0_by_30  \\\n",
       "count             1000000.000000   \n",
       "mean                   29.491030   \n",
       "std                     2.831175   \n",
       "min                     1.304348   \n",
       "25%                    30.000000   \n",
       "50%                    30.000000   \n",
       "75%                    30.000000   \n",
       "max                    30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_dob_homephone_60  \\\n",
       "count                                 1000000.000000   \n",
       "mean                                        1.044485   \n",
       "std                                         0.617953   \n",
       "min                                         1.000000   \n",
       "25%                                         1.000000   \n",
       "50%                                         1.000000   \n",
       "75%                                         1.000000   \n",
       "max                                        30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_name_60  \\\n",
       "count                            1000000.000000   \n",
       "mean                                   1.038698   \n",
       "std                                    0.613817   \n",
       "min                                    1.000000   \n",
       "25%                                    1.000000   \n",
       "50%                                    1.000000   \n",
       "75%                                    1.000000   \n",
       "max                                   30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_lastname_60  \\\n",
       "count                                1000000.000000   \n",
       "mean                                       1.038636   \n",
       "std                                        0.613757   \n",
       "min                                        1.000000   \n",
       "25%                                        1.000000   \n",
       "50%                                        1.000000   \n",
       "75%                                        1.000000   \n",
       "max                                       30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_60  ...  \\\n",
       "count                       1000000.000000  ...   \n",
       "mean                              1.038559  ...   \n",
       "std                               0.613686  ...   \n",
       "min                               1.000000  ...   \n",
       "25%                               1.000000  ...   \n",
       "50%                               1.000000  ...   \n",
       "75%                               1.000000  ...   \n",
       "max                              30.000000  ...   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_lastname_30  \\\n",
       "count                                1000000.000000   \n",
       "mean                                       1.036291   \n",
       "std                                        0.608074   \n",
       "min                                        1.000000   \n",
       "25%                                        1.000000   \n",
       "50%                                        1.000000   \n",
       "75%                                        1.000000   \n",
       "max                                       30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_fulladdress_30  \\\n",
       "count                                   1000000.000000   \n",
       "mean                                          1.036240   \n",
       "std                                           0.608032   \n",
       "min                                           1.000000   \n",
       "25%                                           1.000000   \n",
       "50%                                           1.000000   \n",
       "75%                                           1.000000   \n",
       "max                                          30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_30  \\\n",
       "count                       1000000.000000   \n",
       "mean                              1.036240   \n",
       "std                               0.608032   \n",
       "min                               1.000000   \n",
       "25%                               1.000000   \n",
       "50%                               1.000000   \n",
       "75%                               1.000000   \n",
       "max                              30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_zip5_30  \\\n",
       "count                            1000000.000000   \n",
       "mean                                   1.036240   \n",
       "std                                    0.608032   \n",
       "min                                    1.000000   \n",
       "25%                                    1.000000   \n",
       "50%                                    1.000000   \n",
       "75%                                    1.000000   \n",
       "max                                   30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_name_dob_30  \\\n",
       "count                                1000000.000000   \n",
       "mean                                       1.038982   \n",
       "std                                        0.610242   \n",
       "min                                        1.000000   \n",
       "25%                                        1.000000   \n",
       "50%                                        1.000000   \n",
       "75%                                        1.000000   \n",
       "max                                       30.000000   \n",
       "\n",
       "       fulladdress_count_0_by_14  \\\n",
       "count             1000000.000000   \n",
       "mean                   13.866195   \n",
       "std                     1.015231   \n",
       "min                     0.636364   \n",
       "25%                    14.000000   \n",
       "50%                    14.000000   \n",
       "75%                    14.000000   \n",
       "max                    14.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_name_fulladdress_30  \\\n",
       "count                                    1000000.000000   \n",
       "mean                                           1.035916   \n",
       "std                                            0.607661   \n",
       "min                                            1.000000   \n",
       "25%                                            1.000000   \n",
       "50%                                            1.000000   \n",
       "75%                                            1.000000   \n",
       "max                                           30.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_name_dob_30  name_dob_count_30  \\\n",
       "count                            1000000.000000     1000000.000000   \n",
       "mean                                   1.038716           1.046295   \n",
       "std                                    0.609942           0.496914   \n",
       "min                                    1.000000           1.000000   \n",
       "25%                                    1.000000           1.000000   \n",
       "50%                                    1.000000           1.000000   \n",
       "75%                                    1.000000           1.000000   \n",
       "max                                   30.000000          34.000000   \n",
       "\n",
       "       ssn_name_dob_count_30  \n",
       "count         1000000.000000  \n",
       "mean                1.045940  \n",
       "std                 0.496147  \n",
       "min                 1.000000  \n",
       "25%                 1.000000  \n",
       "50%                 1.000000  \n",
       "75%                 1.000000  \n",
       "max                34.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_scaling = vars.drop(columns = ['record','Fraud'])\n",
    "X_no_scaling.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_count_30</th>\n",
       "      <th>ssn_firstname_count_30</th>\n",
       "      <th>homephone_count_3</th>\n",
       "      <th>ssn_dob_count_30</th>\n",
       "      <th>fulladdress_homephone_count_30</th>\n",
       "      <th>fulladdress_count_0_by_30</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_name_60</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_lastname_60</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_60</th>\n",
       "      <th>...</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_lastname_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_fulladdress_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_zip5_30</th>\n",
       "      <th>fulladdress_unique_count_for_ssn_name_dob_30</th>\n",
       "      <th>fulladdress_count_0_by_14</th>\n",
       "      <th>fulladdress_unique_count_for_name_fulladdress_30</th>\n",
       "      <th>fulladdress_unique_count_for_name_dob_30</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>ssn_name_dob_count_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.018176</td>\n",
       "      <td>-0.017457</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>-0.017649</td>\n",
       "      <td>-0.018020</td>\n",
       "      <td>-8.709183e-14</td>\n",
       "      <td>-0.019380</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-0.019730</td>\n",
       "      <td>-0.019736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019873</td>\n",
       "      <td>-0.019877</td>\n",
       "      <td>-0.019877</td>\n",
       "      <td>-0.019877</td>\n",
       "      <td>-0.019712</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>-0.019904</td>\n",
       "      <td>-0.019734</td>\n",
       "      <td>-0.017617</td>\n",
       "      <td>-0.017661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.631721</td>\n",
       "      <td>0.579481</td>\n",
       "      <td>0.910935</td>\n",
       "      <td>0.571302</td>\n",
       "      <td>0.576299</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.591268</td>\n",
       "      <td>0.579574</td>\n",
       "      <td>0.579416</td>\n",
       "      <td>0.579228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572438</td>\n",
       "      <td>0.572323</td>\n",
       "      <td>0.572323</td>\n",
       "      <td>0.572323</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.975046</td>\n",
       "      <td>0.571322</td>\n",
       "      <td>0.577521</td>\n",
       "      <td>0.572884</td>\n",
       "      <td>0.570790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.097996</td>\n",
       "      <td>-0.521454</td>\n",
       "      <td>-0.092879</td>\n",
       "      <td>-0.094955</td>\n",
       "      <td>-9.955826e+00</td>\n",
       "      <td>-0.071988</td>\n",
       "      <td>-0.063045</td>\n",
       "      <td>-0.062950</td>\n",
       "      <td>-0.062832</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059682</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>-0.063880</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-0.059105</td>\n",
       "      <td>-0.063475</td>\n",
       "      <td>-0.093165</td>\n",
       "      <td>-0.092594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.097996</td>\n",
       "      <td>-0.521454</td>\n",
       "      <td>-0.092879</td>\n",
       "      <td>-0.094955</td>\n",
       "      <td>1.797736e-01</td>\n",
       "      <td>-0.071988</td>\n",
       "      <td>-0.063045</td>\n",
       "      <td>-0.062950</td>\n",
       "      <td>-0.062832</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059682</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>-0.063880</td>\n",
       "      <td>0.131798</td>\n",
       "      <td>-0.059105</td>\n",
       "      <td>-0.063475</td>\n",
       "      <td>-0.093165</td>\n",
       "      <td>-0.092594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.097996</td>\n",
       "      <td>-0.521454</td>\n",
       "      <td>-0.092879</td>\n",
       "      <td>-0.094955</td>\n",
       "      <td>1.797736e-01</td>\n",
       "      <td>-0.071988</td>\n",
       "      <td>-0.063045</td>\n",
       "      <td>-0.062950</td>\n",
       "      <td>-0.062832</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059682</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>-0.063880</td>\n",
       "      <td>0.131798</td>\n",
       "      <td>-0.059105</td>\n",
       "      <td>-0.063475</td>\n",
       "      <td>-0.093165</td>\n",
       "      <td>-0.092594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.097996</td>\n",
       "      <td>0.639148</td>\n",
       "      <td>-0.092879</td>\n",
       "      <td>-0.094955</td>\n",
       "      <td>1.797736e-01</td>\n",
       "      <td>-0.071988</td>\n",
       "      <td>-0.063045</td>\n",
       "      <td>-0.062950</td>\n",
       "      <td>-0.062832</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059682</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>-0.059602</td>\n",
       "      <td>-0.063880</td>\n",
       "      <td>0.131798</td>\n",
       "      <td>-0.059105</td>\n",
       "      <td>-0.063475</td>\n",
       "      <td>-0.093165</td>\n",
       "      <td>-0.092594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.797736e-01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.131798</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fulladdress_count_30  ssn_firstname_count_30  homephone_count_3  \\\n",
       "count        1000000.000000          1000000.000000     1000000.000000   \n",
       "mean              -0.018176               -0.017457          -0.005814   \n",
       "std                0.631721                0.579481           0.910935   \n",
       "min               -0.101958               -0.097996          -0.521454   \n",
       "25%               -0.101958               -0.097996          -0.521454   \n",
       "50%               -0.101958               -0.097996          -0.521454   \n",
       "75%               -0.101958               -0.097996           0.639148   \n",
       "max               10.000000               10.000000          10.000000   \n",
       "\n",
       "       ssn_dob_count_30  fulladdress_homephone_count_30  \\\n",
       "count    1000000.000000                  1000000.000000   \n",
       "mean          -0.017649                       -0.018020   \n",
       "std            0.571302                        0.576299   \n",
       "min           -0.092879                       -0.094955   \n",
       "25%           -0.092879                       -0.094955   \n",
       "50%           -0.092879                       -0.094955   \n",
       "75%           -0.092879                       -0.094955   \n",
       "max           10.000000                       10.000000   \n",
       "\n",
       "       fulladdress_count_0_by_30  \\\n",
       "count               1.000000e+06   \n",
       "mean               -8.709183e-14   \n",
       "std                 1.000000e+00   \n",
       "min                -9.955826e+00   \n",
       "25%                 1.797736e-01   \n",
       "50%                 1.797736e-01   \n",
       "75%                 1.797736e-01   \n",
       "max                 1.797736e-01   \n",
       "\n",
       "       fulladdress_unique_count_for_dob_homephone_60  \\\n",
       "count                                 1000000.000000   \n",
       "mean                                       -0.019380   \n",
       "std                                         0.591268   \n",
       "min                                        -0.071988   \n",
       "25%                                        -0.071988   \n",
       "50%                                        -0.071988   \n",
       "75%                                        -0.071988   \n",
       "max                                        10.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_name_60  \\\n",
       "count                            1000000.000000   \n",
       "mean                                  -0.019726   \n",
       "std                                    0.579574   \n",
       "min                                   -0.063045   \n",
       "25%                                   -0.063045   \n",
       "50%                                   -0.063045   \n",
       "75%                                   -0.063045   \n",
       "max                                   10.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_lastname_60  \\\n",
       "count                                1000000.000000   \n",
       "mean                                      -0.019730   \n",
       "std                                        0.579416   \n",
       "min                                       -0.062950   \n",
       "25%                                       -0.062950   \n",
       "50%                                       -0.062950   \n",
       "75%                                       -0.062950   \n",
       "max                                       10.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_60  ...  \\\n",
       "count                       1000000.000000  ...   \n",
       "mean                             -0.019736  ...   \n",
       "std                               0.579228  ...   \n",
       "min                              -0.062832  ...   \n",
       "25%                              -0.062832  ...   \n",
       "50%                              -0.062832  ...   \n",
       "75%                              -0.062832  ...   \n",
       "max                              10.000000  ...   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_lastname_30  \\\n",
       "count                                1000000.000000   \n",
       "mean                                      -0.019873   \n",
       "std                                        0.572438   \n",
       "min                                       -0.059682   \n",
       "25%                                       -0.059682   \n",
       "50%                                       -0.059682   \n",
       "75%                                       -0.059682   \n",
       "max                                       10.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_fulladdress_30  \\\n",
       "count                                   1000000.000000   \n",
       "mean                                         -0.019877   \n",
       "std                                           0.572323   \n",
       "min                                          -0.059602   \n",
       "25%                                          -0.059602   \n",
       "50%                                          -0.059602   \n",
       "75%                                          -0.059602   \n",
       "max                                          10.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_30  \\\n",
       "count                       1000000.000000   \n",
       "mean                             -0.019877   \n",
       "std                               0.572323   \n",
       "min                              -0.059602   \n",
       "25%                              -0.059602   \n",
       "50%                              -0.059602   \n",
       "75%                              -0.059602   \n",
       "max                              10.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_zip5_30  \\\n",
       "count                            1000000.000000   \n",
       "mean                                  -0.019877   \n",
       "std                                    0.572323   \n",
       "min                                   -0.059602   \n",
       "25%                                   -0.059602   \n",
       "50%                                   -0.059602   \n",
       "75%                                   -0.059602   \n",
       "max                                   10.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_ssn_name_dob_30  \\\n",
       "count                                1000000.000000   \n",
       "mean                                      -0.019712   \n",
       "std                                        0.578313   \n",
       "min                                       -0.063880   \n",
       "25%                                       -0.063880   \n",
       "50%                                       -0.063880   \n",
       "75%                                       -0.063880   \n",
       "max                                       10.000000   \n",
       "\n",
       "       fulladdress_count_0_by_14  \\\n",
       "count             1000000.000000   \n",
       "mean                    0.002262   \n",
       "std                     0.975046   \n",
       "min                   -10.000000   \n",
       "25%                     0.131798   \n",
       "50%                     0.131798   \n",
       "75%                     0.131798   \n",
       "max                     0.131798   \n",
       "\n",
       "       fulladdress_unique_count_for_name_fulladdress_30  \\\n",
       "count                                    1000000.000000   \n",
       "mean                                          -0.019904   \n",
       "std                                            0.571322   \n",
       "min                                           -0.059105   \n",
       "25%                                           -0.059105   \n",
       "50%                                           -0.059105   \n",
       "75%                                           -0.059105   \n",
       "max                                           10.000000   \n",
       "\n",
       "       fulladdress_unique_count_for_name_dob_30  name_dob_count_30  \\\n",
       "count                            1000000.000000     1000000.000000   \n",
       "mean                                  -0.019734          -0.017617   \n",
       "std                                    0.577521           0.572884   \n",
       "min                                   -0.063475          -0.093165   \n",
       "25%                                   -0.063475          -0.093165   \n",
       "50%                                   -0.063475          -0.093165   \n",
       "75%                                   -0.063475          -0.093165   \n",
       "max                                   10.000000          10.000000   \n",
       "\n",
       "       ssn_name_dob_count_30  \n",
       "count         1000000.000000  \n",
       "mean               -0.017661  \n",
       "std                 0.570790  \n",
       "min                -0.092594  \n",
       "25%                -0.092594  \n",
       "50%                -0.092594  \n",
       "75%                -0.092594  \n",
       "max                10.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push in any outlier values\n",
    "cols = X.columns\n",
    "X.loc[:,cols] = X[cols].clip(upper=Clip)\n",
    "X.loc[:,cols] = X[cols].clip(lower=-1*Clip)\n",
    "# X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate data into modeling (traintest) and out of time\n",
    "X_trntst = X[0:833507]\n",
    "Y_trntst = Y_save[0:833507]\n",
    "X_oot = X[833507:]\n",
    "Y_oot = Y_save[833507:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "niter = 0\n",
    "nitermax = 3\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "X_oot_orig = X_oot.copy()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "good\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "good\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "good\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "good\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "bad_model\n",
      "CPU times: user 1h 16min 30s, sys: 43 s, total: 1h 17min 13s\n",
      "Wall time: 58min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression\n",
    "log = pd.DataFrame(columns=['num_vars','penalty','solver','c','train','test','oot'])\n",
    "number_var = []\n",
    "penalty_num = []\n",
    "solver_type = []\n",
    "c_value = []\n",
    "train_value = []\n",
    "test_value = []\n",
    "oot_value = []\n",
    "for num_vars in [5,10,15,20,25]:\n",
    "    X_trntst_new = X_trntst.iloc[:,:num_vars+1]\n",
    "    X_oot_new = X_oot_orig.iloc[:,:num_vars+1]\n",
    "    print('good')\n",
    "    for penalty in ['l1','l2','elasticnet']:\n",
    "        for solver in ['lbfgs','saga']:\n",
    "            for c in [0.1,0.6,1,5]:\n",
    "                try:\n",
    "                    for niter in range(nitermax):    \n",
    "                        X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_new, Y_trntst, test_size = .3)\n",
    "\n",
    "                        model = LogisticRegression(penalty=penalty,solver=solver,C=c)\n",
    "\n",
    "                        X_oot = X_oot_orig.copy()\n",
    "                        X_trn_save = X_trn.copy()\n",
    "                        Y_trn_save = Y_trn.copy()\n",
    "\n",
    "                        model.fit(X_trn, Y_trn.values.ravel())   \n",
    "                        predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "                        X_trn['predicted'] = predictions\n",
    "                        X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "                        topRows = int(round(X_trn.shape[0]*0.03))\n",
    "                        temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "                        needed = temp.loc[:,'Fraud']\n",
    "                        FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "                        predictions = model.predict_proba(X_tst)[:,1]\n",
    "                        X_tst['predicted']=predictions\n",
    "                        X_tst['Fraud'] = Y_tst['Fraud']\n",
    "                        topRows = int(round(X_tst.shape[0]*0.03))\n",
    "                        temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "                        needed = temp.loc[:,'Fraud']\n",
    "                        FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "                        predictions = model.predict_proba(X_oot_new)[:,1]\n",
    "                        X_oot['predicted']=predictions\n",
    "                        X_oot['Fraud'] = Y_oot['Fraud']\n",
    "                        topRows = int(round(X_oot.shape[0]*0.03))\n",
    "                        temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "                        needed = temp.loc[:,'Fraud']\n",
    "                        FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "                    number_var.append(num_vars)\n",
    "                    penalty_num.append(penalty)\n",
    "                    solver_type.append(solver)\n",
    "                    c_value.append(c)\n",
    "                    train_value.append(round(FDR3.mean()[0]*100,2))\n",
    "                    test_value.append(round(FDR3.mean()[1]*100,2))\n",
    "                    oot_value.append(round(FDR3.mean()[2]*100,2))\n",
    "                    print(\"finished!\")\n",
    "                except:\n",
    "                    print('bad_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm = pd.DataFrame(data={'num_vars':number_var,'penalty':penalty_num,'solver':solver_type,'c':c_value,'train':train_value,'test':test_value,'oot':oot_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm.to_excel(\"ligstic.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models. You can comment out any of these cells and just explore one model type. You can also just rerun that single cell multiple times as you explore different model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "CPU times: user 11min 23s, sys: 1min 55s, total: 13min 19s\n",
      "Wall time: 13min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Single DT\n",
    "number_var = []\n",
    "criterion_type = []\n",
    "splitter_type = []\n",
    "max_depth_num= []\n",
    "min_samples_leaf_num = []\n",
    "train_value = []\n",
    "test_value = []\n",
    "oot_value = []\n",
    "for num_vars in [5,10,15,20,25]:\n",
    "    X_trntst_new = X_trntst.iloc[:,:num_vars+1]\n",
    "    X_oot_new = X_oot_orig.iloc[:,:num_vars+1]\n",
    "    print('good')\n",
    "    for criterion in ['gini','entropy']:\n",
    "        for splitter in ['best','random']:\n",
    "            for max_depth in [10,20,None]:\n",
    "                for min_samples_leaf in [1,20,30,40]:\n",
    "                    try:\n",
    "                        for niter in range(nitermax):    \n",
    "                            X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_new, Y_trntst, test_size = .3)\n",
    "\n",
    "                            model = DecisionTreeClassifier(criterion=criterion,splitter=splitter,max_depth=max_depth,min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "                            X_oot = X_oot_orig.copy()\n",
    "                            X_trn_save = X_trn.copy()\n",
    "                            Y_trn_save = Y_trn.copy()\n",
    "\n",
    "                            model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "                            predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "                            X_trn['predicted'] = predictions\n",
    "                            X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "                            topRows = int(round(X_trn.shape[0]*0.03))\n",
    "                            temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_tst)[:,1]\n",
    "                            X_tst['predicted']=predictions\n",
    "                            X_tst['Fraud'] = Y_tst['Fraud']\n",
    "                            topRows = int(round(X_tst.shape[0]*0.03))\n",
    "                            temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_oot_new)[:,1]\n",
    "                            X_oot['predicted']=predictions\n",
    "                            X_oot['Fraud'] = Y_oot['Fraud']\n",
    "                            topRows = int(round(X_oot.shape[0]*0.03))\n",
    "                            temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "                        number_var.append(num_vars)\n",
    "                        criterion_type.append(criterion)\n",
    "                        splitter_type.append(splitter)\n",
    "                        max_depth_num.append(max_depth)\n",
    "                        min_samples_leaf_num.append(min_samples_leaf)\n",
    "                        train_value.append(round(FDR3.mean()[0]*100,2))\n",
    "                        test_value.append(round(FDR3.mean()[1]*100,2))\n",
    "                        oot_value.append(round(FDR3.mean()[2]*100,2))\n",
    "                        print(\"finished!\")\n",
    "                    except:\n",
    "                        print(\"bad model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.DataFrame(data={'num_vars':number_var,'criterion':criterion_type,'splitter':splitter_type,'max_depth':max_depth_num,'min_samples_leaf':min_samples_leaf_num,'train':train_value,'test':test_value,'oot':oot_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.to_excel(\"decision_tree.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "CPU times: user 1h 29min 16s, sys: 3min 8s, total: 1h 32min 25s\n",
      "Wall time: 1h 32min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RF\n",
    "number_var = []\n",
    "criterion_type = []\n",
    "n_estimators_num = []\n",
    "max_depth_num= []\n",
    "max_features_num = []\n",
    "train_value = []\n",
    "test_value = []\n",
    "oot_value = []\n",
    "for num_vars in [20,25]:\n",
    "    X_trntst_new = X_trntst.iloc[:,:num_vars+1]\n",
    "    X_oot_new = X_oot_orig.iloc[:,:num_vars+1]\n",
    "    print('good')\n",
    "    for n_estimators in [10,50,100,150]:\n",
    "        for max_depth in [10,20,30]:\n",
    "            for cirterion in ['gini','entropy']:\n",
    "                for max_features in [\"auto\",\"log2\"]:\n",
    "                    try:\n",
    "                        for niter in range(nitermax):    \n",
    "                            X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_new, Y_trntst, test_size = .3)\n",
    "\n",
    "                            model = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth,criterion=criterion,max_features=max_features)\n",
    "                            X_oot = X_oot_orig.copy()\n",
    "                            X_trn_save = X_trn.copy()\n",
    "                            Y_trn_save = Y_trn.copy()\n",
    "\n",
    "                            model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "                            predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "                            X_trn['predicted'] = predictions\n",
    "                            X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "                            topRows = int(round(X_trn.shape[0]*0.03))\n",
    "                            temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_tst)[:,1]\n",
    "                            X_tst['predicted']=predictions\n",
    "                            X_tst['Fraud'] = Y_tst['Fraud']\n",
    "                            topRows = int(round(X_tst.shape[0]*0.03))\n",
    "                            temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_oot_new)[:,1]\n",
    "                            X_oot['predicted']=predictions\n",
    "                            X_oot['Fraud'] = Y_oot['Fraud']\n",
    "                            topRows = int(round(X_oot.shape[0]*0.03))\n",
    "                            temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "                            \n",
    "                        number_var.append(num_vars)\n",
    "                        criterion_type.append(criterion)\n",
    "                        n_estimators_num.append(n_estimators)\n",
    "                        max_depth_num.append(max_depth)\n",
    "                        max_features_num.append(max_features)\n",
    "                        train_value.append(round(FDR3.mean()[0]*100,2))\n",
    "                        test_value.append(round(FDR3.mean()[1]*100,2))\n",
    "                        oot_value.append(round(FDR3.mean()[2]*100,2))\n",
    "                        print(\"finished!\")\n",
    "                    except:\n",
    "                        print(\"bad model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pd.DataFrame(data={'num_vars':number_var,'criterion':criterion_type,'n_estimators':n_estimators_num,'max_depth':max_depth_num,'max_features':max_features_num,'train':train_value,'test':test_value,'oot':oot_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.to_excel('rf.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "good\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "CPU times: user 18h 30min 36s, sys: 17min 34s, total: 18h 48min 10s\n",
      "Wall time: 3h 29min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# BT\n",
    "number_var = []\n",
    "learning_rate_num = []\n",
    "n_estimators_num = []\n",
    "max_depth_num= []\n",
    "subsample_num = []\n",
    "train_value = []\n",
    "test_value = []\n",
    "oot_value = []\n",
    "for num_vars in [20,25]:\n",
    "    X_trntst_new = X_trntst.iloc[:,:num_vars+1]\n",
    "    X_oot_new = X_oot_orig.iloc[:,:num_vars+1]\n",
    "    print('good')\n",
    "    for n_estimators in [100,200,500,1000]:\n",
    "        for max_depth in [3,4,5]:\n",
    "            for learning_rate in [0.001,0.01,0.02,0.05,0.1]:\n",
    "                for subsample in [0.7,0.8,1]:\n",
    "                    try:\n",
    "                        for niter in range(nitermax):    \n",
    "                            X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_new, Y_trntst, test_size = .3)\n",
    "\n",
    "                            model = lgb.LGBMClassifier(n_estimators=n_estimators,max_depth=max_depth,learning_rate=learning_rate,subsample=subsample)\n",
    "\n",
    "                            X_oot = X_oot_orig.copy()\n",
    "                            X_trn_save = X_trn.copy()\n",
    "                            Y_trn_save = Y_trn.copy()\n",
    "\n",
    "                            model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "                            predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "                            X_trn['predicted'] = predictions\n",
    "                            X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "                            topRows = int(round(X_trn.shape[0]*0.03))\n",
    "                            temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_tst)[:,1]\n",
    "                            X_tst['predicted']=predictions\n",
    "                            X_tst['Fraud'] = Y_tst['Fraud']\n",
    "                            topRows = int(round(X_tst.shape[0]*0.03))\n",
    "                            temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_oot_new)[:,1]\n",
    "                            X_oot['predicted']=predictions\n",
    "                            X_oot['Fraud'] = Y_oot['Fraud']\n",
    "                            topRows = int(round(X_oot.shape[0]*0.03))\n",
    "                            temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "                            \n",
    "                        number_var.append(num_vars)\n",
    "                        learning_rate_num.append(learning_rate)\n",
    "                        n_estimators_num.append(n_estimators)\n",
    "                        max_depth_num.append(max_depth)\n",
    "                        subsample_num.append(subsample)\n",
    "                        train_value.append(round(FDR3.mean()[0]*100,2))\n",
    "                        test_value.append(round(FDR3.mean()[1]*100,2))\n",
    "                        oot_value.append(round(FDR3.mean()[2]*100,2))\n",
    "                        print(\"finished!\")\n",
    "                    except:\n",
    "                        print(\"bad model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = pd.DataFrame(data={'num_vars':number_var,'learning_rate':learning_rate_num,'n_estimators':n_estimators_num,'max_depth':max_depth_num,'subsample':subsample_num,'train':train_value,'test':test_value,'oot':oot_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.to_excel(\"bt.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "finished!\n",
      "CPU times: user 2h 38min 46s, sys: 2min 6s, total: 2h 40min 53s\n",
      "Wall time: 1h 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NN\n",
    "number_var = []\n",
    "hidden_layer_size_num = []\n",
    "max_iter_num = []\n",
    "learning_rate_type = []\n",
    "train_value = []\n",
    "test_value = []\n",
    "oot_value = []\n",
    "for num_vars in [20,25]:\n",
    "    X_trntst_new = X_trntst.iloc[:,:num_vars+1]\n",
    "    X_oot_new = X_oot_orig.iloc[:,:num_vars+1]\n",
    "    print('good')\n",
    "    for hidden_layer_sizes in [(5),(10),(20)]:\n",
    "        for max_iter in [20,50,100]:\n",
    "            for learning_rate in ['constant', 'invscaling', 'adaptive']:\n",
    "                    try:\n",
    "                        for niter in range(nitermax):    \n",
    "                            X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_new, Y_trntst, test_size = .3)\n",
    "\n",
    "                            model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,max_iter=max_iter,learning_rate=learning_rate)\n",
    "\n",
    "                            X_oot = X_oot_orig.copy()\n",
    "                            X_trn_save = X_trn.copy()\n",
    "                            Y_trn_save = Y_trn.copy()\n",
    "\n",
    "                            model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "                            predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "                            X_trn['predicted'] = predictions\n",
    "                            X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "                            topRows = int(round(X_trn.shape[0]*0.03))\n",
    "                            temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_tst)[:,1]\n",
    "                            X_tst['predicted']=predictions\n",
    "                            X_tst['Fraud'] = Y_tst['Fraud']\n",
    "                            topRows = int(round(X_tst.shape[0]*0.03))\n",
    "                            temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "                            predictions = model.predict_proba(X_oot_new)[:,1]\n",
    "                            X_oot['predicted']=predictions\n",
    "                            X_oot['Fraud'] = Y_oot['Fraud']\n",
    "                            topRows = int(round(X_oot.shape[0]*0.03))\n",
    "                            temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "                            needed = temp.loc[:,'Fraud']\n",
    "                            FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "                            \n",
    "                        number_var.append(num_vars)\n",
    "                        hidden_layer_size_num.append(hidden_layer_sizes)\n",
    "                        max_iter_num.append(max_iter)\n",
    "                        learning_rate_type.append(learning_rate)\n",
    "                        train_value.append(round(FDR3.mean()[0]*100,2))\n",
    "                        test_value.append(round(FDR3.mean()[1]*100,2))\n",
    "                        oot_value.append(round(FDR3.mean()[2]*100,2))\n",
    "                        print(\"finished!\")\n",
    "                    except:\n",
    "                        print(\"bad model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = pd.DataFrame(data={'num_vars':number_var,'hidden_layer_size':hidden_layer_size_num,'max_iter':max_iter_num,'learning_rate':learning_rate_type,'train':train_value,'test':test_value,'oot':oot_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.to_excel(\"nn.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiyuzhang/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:20:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:20:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:20:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:20:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:21:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:21:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:21:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:21:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:21:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:22:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:22:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:22:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:22:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:23:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:23:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:23:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:23:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:23:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:24:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:24:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:24:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:24:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:24:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:25:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:25:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:25:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:25:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:26:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:26:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:26:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:26:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:26:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:27:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:27:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:27:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:27:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:28:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:28:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:28:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:28:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:28:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:29:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:29:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:29:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:29:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:30:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:30:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:30:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:30:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:31:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:31:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:31:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:31:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:31:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:32:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:32:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:32:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:32:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:33:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:33:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:33:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:33:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:33:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:34:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:34:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:34:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:34:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:35:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:35:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:35:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:35:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:35:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:36:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:36:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:36:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:36:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:37:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:37:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:37:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:37:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:37:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:38:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:38:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:38:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:38:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "[19:39:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:39:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:39:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:40:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:40:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:40:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:40:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:41:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:41:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:41:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:41:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:41:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:42:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:42:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:42:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:42:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:43:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:43:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:43:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:43:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:43:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:44:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:44:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:44:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:45:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:45:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:45:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:46:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:46:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:47:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:47:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:47:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:48:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:48:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:48:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:48:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:48:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:49:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:49:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:49:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:49:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:50:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:50:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:50:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:50:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:50:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:51:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:51:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "good\n",
      "[19:51:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:51:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:52:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:52:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:52:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:53:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:53:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:53:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:53:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:54:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:54:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:54:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:55:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:55:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:55:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:55:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:56:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:56:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:56:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:56:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:57:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:57:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:57:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:58:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:58:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:58:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[19:58:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:59:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:59:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "[19:59:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:59:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:00:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:00:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:00:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:01:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:01:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:01:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:01:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:02:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:02:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:02:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:02:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:03:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:03:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:03:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:04:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:04:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:04:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:05:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:05:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:05:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:05:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:06:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:06:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:06:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:07:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:07:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:07:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:07:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:08:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:08:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:09:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:09:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:09:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:09:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:10:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:10:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:10:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:11:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:11:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:11:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:11:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:12:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:12:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:12:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:12:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:13:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:13:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:13:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:13:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:14:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:15:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:15:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:15:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:15:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:16:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:16:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:16:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:17:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:17:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:17:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:17:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:18:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:18:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:19:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:36:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:37:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:38:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:38:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "[20:39:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:40:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:41:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:41:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:41:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:41:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:42:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:43:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:43:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:43:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:44:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:44:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:44:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:44:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:45:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:45:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "[20:45:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:45:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:46:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "finished!\n",
      "CPU times: user 12h 50min 53s, sys: 8min 42s, total: 12h 59min 36s\n",
      "Wall time: 1h 26min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "number_var = []\n",
    "learning_rate_num = []\n",
    "n_estimators_num = []\n",
    "max_depth_num = []\n",
    "train_value = []\n",
    "test_value = []\n",
    "oot_value = []\n",
    "for num_vars in [20,25]:\n",
    "    X_trntst_new = X_trntst.iloc[:,:num_vars+1]\n",
    "    X_oot_new = X_oot_orig.iloc[:,:num_vars+1]\n",
    "    print('good')\n",
    "    for n_estimators in [80,100,150,200]:\n",
    "        for learning_rate in [0.05,0.1,0.3,0.4]:\n",
    "            for max_depth in [3,4,5]:\n",
    "                try:\n",
    "                    for niter in range(nitermax):    \n",
    "                        X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst_new, Y_trntst, test_size = .3)\n",
    "\n",
    "                        model = XGBClassifier(seed=47)\n",
    "\n",
    "                        X_oot = X_oot_orig.copy()\n",
    "                        X_trn_save = X_trn.copy()\n",
    "                        Y_trn_save = Y_trn.copy()\n",
    "\n",
    "                        model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "                        predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "                        X_trn['predicted'] = predictions\n",
    "                        X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "                        topRows = int(round(X_trn.shape[0]*0.03))\n",
    "                        temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "                        needed = temp.loc[:,'Fraud']\n",
    "                        FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "                        predictions = model.predict_proba(X_tst)[:,1]\n",
    "                        X_tst['predicted']=predictions\n",
    "                        X_tst['Fraud'] = Y_tst['Fraud']\n",
    "                        topRows = int(round(X_tst.shape[0]*0.03))\n",
    "                        temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "                        needed = temp.loc[:,'Fraud']\n",
    "                        FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "                        predictions = model.predict_proba(X_oot_new)[:,1]\n",
    "                        X_oot['predicted']=predictions\n",
    "                        X_oot['Fraud'] = Y_oot['Fraud']\n",
    "                        topRows = int(round(X_oot.shape[0]*0.03))\n",
    "                        temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "                        needed = temp.loc[:,'Fraud']\n",
    "                        FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "\n",
    "                    number_var.append(num_vars)\n",
    "                    learning_rate_num.append(learning_rate)\n",
    "                    n_estimators_num.append(n_estimators)\n",
    "                    max_depth_num.append(max_depth)\n",
    "                    train_value.append(round(FDR3.mean()[0]*100,2))\n",
    "                    test_value.append(round(FDR3.mean()[1]*100,2))\n",
    "                    oot_value.append(round(FDR3.mean()[2]*100,2))\n",
    "                    print(\"finished!\")\n",
    "                except:\n",
    "                    print(\"bad model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = pd.DataFrame(data={'num_vars':number_var,'n_estimators':n_estimators_num,'learning_rate':learning_rate_num,'max_depth':max_depth_num,'train':train_value,'test':test_value,'oot':oot_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.to_excel('xgboost.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:03:48.900114\n"
     ]
    }
   ],
   "source": [
    "print('duration: ', datetime.now() - start_time)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
